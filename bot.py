import os
import csv
import re
from collections import Counter
from aiogram import Bot, Dispatcher, F
from aiogram.types import Message, ReplyKeyboardMarkup, KeyboardButton
from aiogram.filters import CommandStart

BOT_TOKEN = os.getenv("BOT_TOKEN")

# ---------- –ö–ù–û–ü–ö–ò ----------
start_keyboard = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—Å—Ç")]],
    resize_keyboard=True
)

again_keyboard = ReplyKeyboardMarkup(
    keyboard=[[KeyboardButton(text="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—â—ë")]],
    resize_keyboard=True
)

# ---------- –ß–ï–õ–û–í–ï–ß–ï–°–ö–ò–ï –ù–ê–ó–í–ê–ù–ò–Ø –ö–ê–¢–ï–ì–û–†–ò–ô ----------
CATEGORY_LABELS = {
    "substance": "–≤–µ—â–µ—Å—Ç–≤–æ",
    "action": "–¥–µ–π—Å—Ç–≤–∏–µ —É–ø–æ—Ç—Ä–µ–±–ª–µ–Ω–∏—è",
    "distribution": "–¥–æ–±—ã—á–∞/—Å–±—ã—Ç",
    "paraphernalia": "–∞—Ç—Ä–∏–±—É—Ç–∏–∫–∞",
    "context_positive": "–Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è/—Ä–æ–º–∞–Ω—Ç–∏–∑–∞—Ü–∏—è",
    "context_negative": "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç",
    "state": "—Å–æ—Å—Ç–æ—è–Ω–∏–µ/—ç—Ñ—Ñ–µ–∫—Ç",
    "metaphor": "–º–µ—Ç–∞—Ñ–æ—Ä–∞",
}

# ---------- –ó–ê–ì–†–£–ó–ö–ê –°–õ–û–í–ê–†–Ø ----------
def load_dictionary():
    items = []
    with open("dictionary.csv", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            term = (row.get("term") or "").strip()
            if not term:
                continue

            match_type = (row.get("match_type") or "word").strip().lower()
            category = (row.get("category") or "unknown").strip()
            risk = (row.get("risk") or "low").strip()
            note = (row.get("note") or "").strip()
            exceptions = (row.get("exceptions") or "").strip()

            try:
                weight = int(row.get("weight") or 0)
            except ValueError:
                weight = 0

            items.append({
                "term": term,
                "match_type": match_type,
                "category": category,
                "risk": risk,
                "weight": weight,
                "note": note,
                "exceptions": exceptions,
            })
    return items

DICTIONARY = load_dictionary()

# ---------- –ê–ù–ê–õ–ò–ó ----------
def normalize(text: str) -> str:
    text = text.lower().replace("—ë", "–µ")
    text = re.sub(r"[^\w\s]", " ", text, flags=re.UNICODE)
    text = re.sub(r"\s+", " ", text).strip()
    return text

def exceptions_hit(exceptions: str, context: str) -> bool:
    if not exceptions:
        return False
    parts = [p.strip().lower().replace("—ë", "–µ") for p in exceptions.split("|") if p.strip()]
    ctx = context.lower().replace("—ë", "–µ")
    return any(p in ctx for p in parts)

def find_hits(text: str):
    t = normalize(text)
    hits = []

    for e in DICTIONARY:
        term = e["term"]
        mt = e["match_type"]

        if mt == "regex":
            pattern = term
        else:
            # word/phrase: –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞
            pattern = r"\b" + re.escape(term.lower().replace("—ë", "–µ")) + r"\b"

        try:
            for m in re.finditer(pattern, t):
                context = t[max(0, m.start() - 70): min(len(t), m.end() + 70)]
                if exceptions_hit(e.get("exceptions", ""), context):
                    continue

                hits.append({
                    "term": term,                # –∫–∞–∫ –≤ —Å–ª–æ–≤–∞—Ä–µ
                    "matched": m.group(0),        # —á—Ç–æ —Ä–µ–∞–ª—å–Ω–æ –≤—Å—Ç—Ä–µ—Ç–∏–ª–æ—Å—å
                    "category": e["category"],
                    "risk": e["risk"],
                    "weight": e["weight"],
                    "note": e["note"],
                    "start": m.start(),
                })
        except re.error:
            # –µ—Å–ª–∏ regex –≤ —Å–ª–æ–≤–∞—Ä–µ –∫—Ä–∏–≤–æ–π ‚Äî –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–ø—É—Å–∫–∞–µ–º
            continue

    # –¥–µ–¥—É–ø —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    uniq = {}
    for h in hits:
        key = (h["term"], h["start"])
        uniq[key] = h

    return sorted(uniq.values(), key=lambda x: (x["start"], -x["weight"]))

def score_and_reasons(hits):
    total = sum(h["weight"] for h in hits)
    cats = set(h["category"] for h in hits)

    has_substance = "substance" in cats
    has_action = "action" in cats
    has_positive = "context_positive" in cats

    reasons = []

    # –°—Ü–µ–Ω–∞: –≤–µ—â–µ—Å—Ç–≤–æ + –¥–µ–π—Å—Ç–≤–∏–µ
    if has_substance and has_action:
        total += 10
        reasons.append("–µ—Å—Ç—å —Å–æ—á–µ—Ç–∞–Ω–∏–µ ¬´–≤–µ—â–µ—Å—Ç–≤–æ + –¥–µ–π—Å—Ç–≤–∏–µ¬ª")

    # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è: –≤–µ—â–µ—Å—Ç–≤–æ + –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π –º–∞—Ä–∫–µ—Ä
    if has_substance and has_positive:
        total += 6
        reasons.append("–µ—Å—Ç—å –º–∞—Ä–∫–µ—Ä—ã –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–∏ —Ä—è–¥–æ–º —Å —Ç–µ–º–æ–π")

    # –ü–ª–æ—Ç–Ω–æ—Å—Ç—å/–º–∞—Å—à—Ç–∞–±: –º–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π
    if len(hits) >= 4:
        total += 4
        reasons.append("–º–Ω–æ–≥–æ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ —Ç–µ–º–µ")

    if total >= 25:
        return "–í–´–°–û–ö–ò–ô", total, reasons
    if total >= 10:
        return "–°–†–ï–î–ù–ò–ô", total, reasons
    if total > 0:
        return "–ù–ò–ó–ö–ò–ô", total, reasons
    return "–ù–ï –û–ë–ù–ê–†–£–ñ–ï–ù–û", total, reasons

# ---------- –û–¢–ß–Å–¢ ----------
def build_report(text: str):
    hits = find_hits(text)
    level, total, reasons = score_and_reasons(hits)

    cat_counter = Counter([h["category"] for h in hits])

    lines = []
    lines.append(f"üü• –£—Ä–æ–≤–µ–Ω—å —Ä–∏—Å–∫–∞: {level}")
    lines.append("")
    lines.append(f"üìä –°–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(hits)} | –ë–∞–ª–ª: {total}")

    if cat_counter:
        lines.append("–ö–∞—Ç–µ–≥–æ—Ä–∏–∏:")
        for c, n in cat_counter.most_common():
            lines.append(f"‚Äî {CATEGORY_LABELS.get(c, c)}: {n}")
        lines.append("")

    if reasons:
        lines.append("üìå –ü–æ—á–µ–º—É —Ç–∞–∫:")
        for r in reasons:
            lines.append(f"‚Äî {r}")
        lines.append("")

    if hits:
        lines.append("üîç –ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã:")
        for h in hits[:10]:
            shown = h.get("matched") or h["term"]
            cat = CATEGORY_LABELS.get(h["category"], h["category"])
            note = f" ‚Äî {h['note']}" if h.get("note") else ""
            lines.append(f"‚Äî ¬´{shown}¬ª ‚Üí {cat}{note}")
        if len(hits) > 10:
            lines.append(f"‚Ä¶–µ—â—ë —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π: {len(hits) - 10}")
        lines.append("")
    else:
        lines.append("–°–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ —Å–ª–æ–≤–∞—Ä—é –Ω–µ –Ω–∞–π–¥–µ–Ω–æ.")
        lines.append("")

    # –ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è (–∫–æ—Ä–æ—Ç–∫–æ, –±–µ–∑ —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫)
    if level == "–í–´–°–û–ö–ò–ô":
        lines.append("üß† –¢–µ–∫—Å—Ç —Å–æ–¥–µ—Ä–∂–∏—Ç –ø—Ä—è–º—ã–µ –∏–ª–∏ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.")
        lines.append("‚ö†Ô∏è –ü–µ—Ä–µ–¥ –ø—É–±–ª–∏–∫–∞—Ü–∏–µ–π —Å—Ç–æ–∏—Ç —Å–¥–µ–ª–∞—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫.")
    elif level == "–°–†–ï–î–ù–ò–ô":
        lines.append("üß† –û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.")
        lines.append("‚ö†Ô∏è –í–æ–∑–º–æ–∂–Ω—ã –≤–æ–ø—Ä–æ—Å—ã –ø—Ä–∏ –º–æ–¥–µ—Ä–∞—Ü–∏–∏/–ø—Ä–æ–≤–µ—Ä–∫–µ.")
    elif level == "–ù–ò–ó–ö–ò–ô":
        lines.append("üß† –ù–∞–π–¥–µ–Ω—ã –æ—Ç–¥–µ–ª—å–Ω—ã–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è.")
        lines.append("‚ö†Ô∏è –†–∏—Å–∫ –Ω–µ–≤—ã—Å–æ–∫–∏–π, –Ω–æ —Å—Ç–æ–∏—Ç –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç.")
    else:
        lines.append("üß† –°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π –ø–æ —Å–ª–æ–≤–∞—Ä—é –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ.")

    lines.append("")
    lines.append("üìå –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    lines.append("‚Ä¢ –ø—Ä–æ–≤–µ—Ä—å –º–µ—Å—Ç–∞, –≥–¥–µ –≤—Å—Ç—Ä–µ—á–∞—é—Ç—Å—è ¬´–≤–µ—â–µ—Å—Ç–≤–æ + –¥–µ–π—Å—Ç–≤–∏–µ¬ª")
    lines.append("‚Ä¢ –µ—Å–ª–∏ —Ä–µ–ª–∏–∑ –ø—É–±–ª–∏—á–Ω—ã–π/–∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏–π ‚Äî —Å–¥–µ–ª–∞–π —Ñ–∏–Ω–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–µ–∫—Å—Ç–∞")
    lines.append("")
    lines.append("üõ° –î–∏—Å–∫–ª–µ–π–º–µ—Ä: —Å–ø—Ä–∞–≤–æ—á–Ω—ã–π –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –ø–æ —Å–ª–æ–≤–∞—Ä—é. –ù–µ —è–≤–ª—è–µ—Ç—Å—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏–º –∑–∞–∫–ª—é—á–µ–Ω–∏–µ–º.")

    return "\n".join(lines)

# ---------- TELEGRAM ----------
dp = Dispatcher()

@dp.message(CommandStart())
async def start(message: Message):
    await message.answer(
        "–ù–∞–∂–º–∏ ¬´–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—Å—Ç¬ª –∏ –ø—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç —Ç—Ä–µ–∫–∞ –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.",
        reply_markup=start_keyboard
    )

@dp.message(F.text == "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—Å—Ç")
async def ask_text(message: Message):
    await message.answer("–í—Å—Ç–∞–≤—å —Ç–µ–∫—Å—Ç —Ç—Ä–µ–∫–∞ –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.")

@dp.message(F.text == "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—â—ë")
async def again(message: Message):
    await message.answer("–û–∫. –ü—Ä–∏—à–ª–∏ –Ω–æ–≤—ã–π —Ç–µ–∫—Å—Ç –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.")

@dp.message(F.text)
async def handle_text(message: Message):
    text = (message.text or "").strip()

    # –Ω–µ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–æ—Ä–æ—Ç–∫–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –Ω–∞–∂–∞—Ç–∏—è –∫–Ω–æ–ø–æ–∫ –∫–∞–∫ —Ç–µ–∫—Å—Ç —Ç—Ä–µ–∫–∞
    if text in ("–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Ç–µ–∫—Å—Ç", "–ü—Ä–æ–≤–µ—Ä–∏—Ç—å –µ—â—ë"):
        return
    if len(text) < 20:
        await message.answer("–ü—Ä–∏—à–ª–∏ —Ç–µ–∫—Å—Ç –ø–æ–¥–ª–∏–Ω–Ω–µ–µ (—Ö–æ—Ç—è –±—ã 1‚Äì2 —Å—Ç—Ä–æ–∫–∏).")
        return

    report = build_report(text)

    if len(report) > 3800:
        report = report[:3800] + "\n‚Ä¶(–æ–±—Ä–µ–∑–∞–Ω–æ –ø–æ –ª–∏–º–∏—Ç—É Telegram)"

    await message.answer(report, reply_markup=again_keyboard)

async def main():
    if not BOT_TOKEN:
        raise RuntimeError("BOT_TOKEN –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –≤ –æ–∫—Ä—É–∂–µ–Ω–∏–∏. –ü—Ä–æ–≤–µ—Ä—å Railway ‚Üí Variables.")
    bot = Bot(token=BOT_TOKEN)
    await dp.start_polling(bot)

if __name__ == "__main__":
    import asyncio
    asyncio.run(main())
